Super fichier
---
title: "DiD tests"
format: html
---

```{r}
install.packages("devtools")
devtools::install_github("bcallaway11/did", force=TRUE)
library(did)
library(plm)
library(ggplot2)
```

# Two groups / two periods

The "canonical" version of DiD involves two periods and two groups. The untreated group never participates in the treatment, and the treated group becomes treated in the second period.

The leading approach in applied work is to try to estimate the effect of the treatment using a two-way fixed effects (TWFE) linear regression. This works great in the case with two periods, but there are a number of recent methodological papers that suggest that there may be substantial drawbacks to using TWFE with multiple time periods.

## Theory & assumptions

We define the following model:

$$Y_{i,t}=D_i*Y_{i,t}(1)+(1-D_i)Y_{i,t}(0)$$

With :

-   $Y_{i,t}(0)$ the outcome that unit i would experience in period $t$ if they did not participate in the treatment;

-   $Y_{i,t}(1)$ the outcome that unit i would experience in period $t$ if they did participate in the treatment;

-   $D=1$ for units in the treated group and $D=0$ for units in the untreated group.

The main parameter of interest in most DiD designs is the **Average Treatment Effect** on the Treated (ATT). It is given by $$ATT=E[Y_t(1)-Y_t(0)|D=1]$$ This is the difference between treated and untreated potential outcomes, on average, for units in the treated group.

The main assumption in DiD designs is called the **Parallel Trends Assumption**: $$E[Y_t(0)-Y_{t-1}(0)|D=1]=E[Y_t(0)-Y_{t-1}|D=0]$$ In words, this assumption says that the change (or "path") in outcomes over time that units in the treated group would have experienced if they had not participated in the treatment is the same as the path of outcomes that units in the untreated group actually experienced.

Under the parallel trends assumption, the **ATT** is identified and given by $$ATT=E[Y_t-Y_{t-1}|D=1]-E[Y_t-Y_{t-1}|D=0]$$

By far the most common approach to trying to estimate the effect of a binary treatment in this setup is the **Two way fixed effects regressions (TWFE)** linear regression.

$$Y_{i,t}=\theta_t+\eta_i+\alpha D_{i,t}+ \nu_{i,t}$$ where: - $\theta_t$ is a time fixed effect, - $\eta_i$ is a unit fixed effect, - $D_{i,t}$ is a treatment dummy variable, - $\nu_{i,t}$ are time varying unobservables that are mean independent of everything else - $\alpha$ is presumably the parameter of interest. It is often interpreted as the average effect of participating in the treatment.

**When will TWFE work?**

-   **Effects really aren't heterogeneous.** If the effect of participating in the treatment really is $\alpha$ for all units, TWFE will work great.

    That being said, in many applications, treatment effects are very likely to be heterogeneous, they may vary across different units or exhibit dynamics or change across different time periods. In particular applications, this is worth thinking about, but, at least in our view, we think that heterogeneous effects of participating in some treatment is the leading case.

-   **There are only two time periods.** This is the canonical case (2 periods, one group becomes treated in the second period, the other is never treated). In this case, under parallel trends and no-anticipation, $\alpha$ is going to be numerically equal to the ATT. In other words, in this case, even though it looks like you have restricted the effect of participating in the treatment to be the same across all units, TWFE exhibits robustness to treatment effect heterogeneity.

    Unfortunately, this robustness to treatment effect heterogeneity does not continue to hold when there are more periods and groups become treated at different points in time.

## Analysis





# Multiple groups / multiple periods

## Theory & assumptions

### Notations

Now let's move to a more general case where there are $T$ total time periods. Denote particular time periods by $t$ where $t=1,…,T$.

Let's first provide some extended notation:

-   $Y_{i,t}(0)$ is unit i's untreated potential outcome. This is the outcome that unit i would experience in period $t$ if they do not participate in the treatment.

-   $Y_{i,t}(g)$ is unit i's potential outcome in time period $t$ if they become treated in period g.

-   $G_i$ is the time period when unit i becomes treated (often groups are defined by the time period when a unit becomes treated; hence, the G notation).

-   $C_i$ is an indicator variable for whether unit i is in a never-treated group.

-   $D_{i,t}$ is an indicator variable for whether unit i has been treated by time $t$.

-   $Y_{i,t}$ is unit i's observed outcome in time period t.

-   $X_i$ a vector of pre-treatment covariates.

For units in the never-treated group, $Y_{i,t}=Y_{i,t}(0)$ in all time periods. For units in other groups, we observe $$Y_{i,t}=1_{G_i>t}*Y_{i,t}(0)+1_{G_i \leq t}Y_{i,t}(G_i)$$.

### Main assumptions

**Staggered Treatment Adoption Assumption**: Recall that $D_{i,t}=1$ if a unit i has been treated by time t and $D_{i,t}=0$ otherwise. Then, for $t=1,...,T-1$, if $D_{i,t}=1$ then $D_{i,t+1}=1$.

#STAA = Une fois traité, on l'est pour toujours

*Staggered treatment* adoption implies that once a unit participates in the treatment, they remain treated. In other words, units do not "forget" about their treatment experience.

**Parallel Trends Assumption based on never-treated units**: For all $g=2,...,T$ and $t=2,...,T$, with $t\geq g$, we have $$E[Y_t(0)-Y_{t-1}(0)|G=g]=E[Y_t(0)-Y_{t-1}(0)|C=1]$$

This is a natural extension of the parallel trends assumption in the two periods and two groups case. It says that, in the absence of treatment, average untreated potential outcomes for the group first treated in time g and for the "never treated" group would have followed parallel paths in all post-treatment periods $t \geq g$.

#La moyenne des non traités et des traités s'ils n'avaient pas été traités suivent une évolution parallèle

This presumes that **(i)** a (large enough) "never-treated" group is available in the data, and **(ii)** these units are "similar enough" to the eventually treated units such that they can indeed be used as a valid comparison group.

In situations where these conditions are not satisfied, one can use an alternative parallel trends assumption that uses the not-yet treated units as valid comparison groups.

**Parallel Trends Assumption based on not-yet treated units**: For all $g=2,...,T$, $s,t=2,...,T$ with $t \geq g$ and $s \geq t$ we assume $$E[Y_t(0)-Y_{t-1}(0)|G=g]=E[Y_t(0)-Y_{t-1}(0)|D_s=0,G \neq g]$$

In plain English, this assumption states that one can use the not-yet-treated by time s $(s \geq t)$ units as valid comparison groups when computing the average treatment effect for the group first treated in time $g$.

**Parallel Trends Conditional on Covariates**:

In many cases, the parallel trends assumption is substantially more plausible if it holds after conditioning on observed pre-treatment covariates. In other words, if the parallel trends assumptions are modified to be:

-   **Conditional Parallel Trends Assumption based on never-treated units**: For all $g=2,...,T$ and $t=2,...,T$ with $t \geq g$ we get $$E[Y_t(0)-Y_{t-1}(0)|X,G=g]=E[Y_t(0)-Y_{t-1}(0)|X,C=1]$$.

-   **Parallel Trends Assumption based on not-yet treated units**: For all $g=2,...,T$ and $s,t=2,...,T$ with $t \geq g$ and $s \geq t$ we get $$E[Y_t(0)-Y_{t-1}(0)|X,G=g]=E[Y_t(0)-Y_{t-1}(0)|X,D_s=0,G \neq g]$$.

Importantly, this assumptions allow for covariate-specific trends in outcomes across groups, which can be particularly important in setups where the distribution of covariates varies across groups. An example of a case where this assumption is attractive is one where a researcher is interested in estimating the effect of participating in job training on earnings. In that case, if the path of earnings (in the absence of participating in job training) depends on things like education, previous occupation, or years of experience (which it almost certainly does), then it would be important to condition on these types of variables in order to make parallel trends more credible.

### Parameters of interest

**Group-Time Average Treatment Effects**:

A natural way to generalize the parameter of interest (the **ATT**) from the two periods and two groups case to the multiple periods case is to define group-time average treatment effects: $$ATT(g,t)=E[Y_t(g)-Y_t(0)|G=g]$$

This is the average effect of participating in the treatment for units in group $g$ at time period $t$.

Under either version of the parallel trends assumptions mentioned above, it is straightforward to show that group-time average treatment effects are identified:

-   Suppose the parallel trends assumption based on *"never-treated units"*, we have that, for all $t \geq g$, $ATT(g,t)=E[Y_t-Y_{g-1}|G=g]-E[Y_t-Y_{g-1}|C=1]$.

-   Suppose the parallel trends assumption based on *"not-yet-treated units"*, we have that, for all $t \geq g$, $ATT(g,t)=E[Y_t-Y_{g-1}|G=g]-E[Y_t-Y_{g-1}|D_t=0,G \neq g]$.

These group-time average treatment effects are the building blocks of understanding the effect of participating in a treatment in DiD designs with multiple time periods.

When considering parallel trends conditional on some covariates, **ATT** is still the parameter of interest and one needs to estimate the change in outcomes for units in the untreated group conditional on X, but average out X over the distribution of covariates for individuals in group g to obtain $ATT(g,t)$.

**Aggregating Group-Time Average Treatment Effects**:

Group-time average treatment effects are natural parameters to identify in the context of DiD with multiple periods and multiple groups. But in many applications, there may be a lot of them. There are some benefits and costs here. The main benefit is that it is relatively straightforward to think about heterogeneous effects across groups and time using group-time average treatment effects. On the other hand, it can be hard to summarize them (e.g., they are not just a single number).

There are plenty of possible ways to aggregate $ATT(g,t)$:

-   First, consider the average effect of participating in the treatment, separately for each group. This is given by $$\theta_S(g)=\frac{1}{T-g+1} \sum_{t=2}^{T} 1_{g \leq t} ATT(g,t)$$

-   Furthermore, it is fairly straightforward to further aggregate $\theta_S(g)$ to get an easy-to-interpret overall effect parameter, $$\theta^O_S:= \sum_{g=2}^{T} \theta_S(g) P(G=g)$$ $\theta^O_S$ is the overall effect of participating in the treatment across all groups that have ever participated in the treatment. This is close to being a multi-period analogue of the ATT in the two period case.

-   Understanding treatment effect dynamics, in line with event-study-type of analysis. In this case, a natural way to aggregate the group-time average treatment effect to highlight treatment effect dynamics is given by $$\theta_D(e):= \sum_{g=2}^{T} 1_{g+e \leq T} ATT(g,g+e) P(G=g|G+e \leq T)$$

## Analysis

### Simulated data

```{r, echo=FALSE}
set.seed(1814)
```

We simulate a four periods dataset

#On génère un ensemble de données simulé avec 4 périodes temporelles respectant la parralel trend assumption. On utilise la pondération inverse de la probabilité de traitement (IPW). Son objectif est de corriger le biais de sélection car les individus ne sont pas assignés aléatoirement au traitement. Le code génère donc un ensemble données qui respecte les conditions requises pour l'analyse du projet. Ainsi, on regarde à chaque période, l'outcome, peu importe la période à laquelle l'individu a été traité. 

```{r}
# set simulation parameters
# (main thing: it generates a dataset that satisfies
# parallel trends in all periods...including pre-treatment)
time.periods = 4

sim_parameters = reset.sim(time.periods = time.periods, n = 5000, ipw = TRUE, reg = TRUE)

# generate dynamic effects
sim_parameters$te.e = 1:time.periods

# generate data set
data <- build_sim_dataset(sim_parameters)

head(data)
```
#On vérfie que le X et cluster n'ont pas d'impact dans le code
```{r}
# Charger le package dplyr pour utiliser la fonction copy (si vous souhaitez l'utiliser)
library(dplyr)

# Étape 1 : Copier le dataset
copie_dataset <- data.frame(data)
# OU avec dplyr
# copie_dataset <- copy(original_dataset)

# Étape 2 : Mettre à zéro les colonnes choisies
copie_dataset$cluster <- 0
copie_dataset$X <- 0

# Afficher le dataset modifié pour vérification
print(copie_dataset)

```

The function simulates a data set with the following attributes:

-   **G**: observations group
-   **X**: value of covariate
-   **id**: observation's id
-   **cluster**: observation's cluster (by construction there is no within-cluster correlation)
-   **period**: time period for current observation
-   **Y**: outcome
-   **treat**: whether or not this unit is ever treated

### Assumption testing

The objective here is to test the parallel trend assumption.

#### Standard parallel trend assumption testing

-   **Event-study regression approach**:

By far the most common approach to pre-testing in applications is to run an event-study regression. $$Y_{i,t}=\theta_t+\eta_i+\sum_{l=-T}^{T-1} D^l_{i,t} \mu_l + \nu_{i,t}$$ where $D^l_{i,t}=1$ if individual i has been exposed to the treatment for l periods in period t, and $D^l_{i,t}=0$ otherwise and $\mu_l$ is interpreted as the effect of treatment for different lengths of exposure to the treatment.

#Le code ci-dessous crée de nouvelles variables indicatrices, Dtmin et Dt, qui permettent de modéliser les effets statistiques de certaines périodes temporelles. 

```{r}
#-----------------------------------------------------------------------------
# modify the dataset a bit so that we can run an event study
#-----------------------------------------------------------------------------

# generate leads and lags of the treatment
Dtl <- sapply(-(time.periods-1):(time.periods-2), function(l) {
    dtl <- 1*( (data$period == data$G + l) & (data$G > 0) )
    dtl
})
Dtl <- as.data.frame(Dtl)
cnames1 <- paste0("Dtmin", (time.periods-1):1)
colnames(Dtl) <- c(cnames1, paste0("Dt", 0:(time.periods-2)))
data <- cbind.data.frame(data, Dtl)
row.names(data) <- NULL

head(data)
```


```{r}
#-----------------------------------------------------------------------------
# modify the dataset a bit so that we can run an event study
#-----------------------------------------------------------------------------

# generate leads and lags of the treatment

time.periods2 <- 100

Dtl2 <- sapply(-(time.periods2-50):(time.periods2-75), function(l) {
    dtl <- 1*( (data2$period == data2$G + l) & (data2$G > 0) )
    dtl
})
Dtl2 <- as.data.frame(Dtl2)
cnames1 <- paste0("Dtmin", (time.periods2-50):1)

colnames(Dtl2) <- c(cnames1, paste0("Dt", 0:(time.periods2-75)))
data2 <- cbind.data.frame(data2, Dtl2)
row.names(data2) <- NULL

head(data2)
```



#L'objectif de ce code est d'évaluer comment la variable dépendante Y varie par rapport aux différentes périodes temporelles. On normalise à 0 pour mesurer l'impact relatif. 


```{r}
#-----------------------------------------------------------------------------
# run the event study regression
#-----------------------------------------------------------------------------

# run event study regression
# normalize effect to be 0 in pre-treatment period
es <- plm(Y ~ Dtmin3 + Dtmin2 + Dt0 + Dt1 + Dt2, 
          data = data, model = "within", effect = "twoways",
          index = c("id", "period"))

summary(es)
```

```{r}
#-----------------------------------------------------------------------------
# run the event study regression
#-----------------------------------------------------------------------------

# run event study regression
# normalize effect to be 0 in pre-treatment period
es2 <- plm(Y ~ Dtmin50 + Dtmin49 + Dtmin48 + Dtmin47 + Dtmin46 + Dtmin45 + Dtmin44 + Dtmin43 + Dtmin42 + Dtmin41 + Dtmin40 + Dtmin39 + Dtmin38 + Dtmin37 + Dtmin36 + Dtmin35 + Dtmin34 + Dtmin33 + Dtmin32 + Dtmin31 + Dtmin30 + Dtmin29 + Dtmin28 + Dtmin27 + Dtmin26 + Dtmin25 + Dtmin24 + Dtmin23 + Dtmin22 + Dtmin21 + Dtmin20 + Dtmin19 + Dtmin18 + Dtmin17 + Dtmin16 + Dtmin15 + Dtmin14 + Dtmin13 + Dtmin12 + Dtmin11 + Dtmin10 + Dtmin9 + Dtmin8 + Dtmin7 + Dtmin6 + Dtmin5 + Dtmin4 + Dtmin3 + Dtmin2 + Dt0 + Dt1 + Dt2 + Dt3 + Dt4 + Dt5 + Dt6 + Dt7 + Dt8 + Dt9 + Dt10 + Dt11 + Dt12 + Dt13 + Dt14 + Dt15 + Dt16 + Dt17 + Dt18 + Dt19 + Dt20 + Dt21 + Dt22 + Dt23 + Dt24 + Dt25, 
          data = data2, model = "within", effect = "twoways",
          index = c("id", "period"))

summary(es2)
```





#Le code ci-dessous produit un graphique qui permet de visualiser l'évolution de l'effet de chaque période sur la variable. 
```{r}
#-----------------------------------------------------------------------------
# make an event study plot
#-----------------------------------------------------------------------------

# some housekeeping for making the plot
# add 0 at event time -1
coefs1 <- coef(es)
ses1 <- sqrt(diag(summary(es)$vcov))
idx.pre <- 1:(time.periods-2)
idx.post <- (time.periods-1):length(coefs1)
coefs <- c(coefs1[idx.pre], 0, coefs1[idx.post])
ses <- c(ses1[idx.pre], 0, ses1[idx.post])
exposure <- -(time.periods-1):(time.periods-2)

cmat <- data.frame(coefs=coefs, ses=ses, exposure=exposure)

ggplot(data = cmat, mapping = aes(y = coefs, x = exposure)) +
  geom_line(linetype = "dashed") +
  geom_point() + 
  geom_errorbar(aes(ymin = (coefs-1.96*ses), ymax = (coefs+1.96*ses)), width = 0.2) +
  ylim(c(-2, 5)) +
  theme_bw()
```


```{r}
#-----------------------------------------------------------------------------
# make an event study plot
#-----------------------------------------------------------------------------

# some housekeeping for making the plot
# add 0 at event time -1
coefs12 <- coef(es2)
ses12 <- sqrt(diag(summary(es2)$vcov))
idx.pre2 <- 1:(time.periods2-50)
idx.post2 <- (time.periods2-49):length(coefs12)
coefs2 <- c(coefs12[idx.pre2], 0, coefs12[idx.post2])
ses2 <- c(ses1[idx.pre2], 0, ses1[idx.post2])
exposure2 <- -(time.periods2-50):(time.periods2-75)

cmat2 <- data.frame(coefs=coefs2, ses=ses2, exposure=exposure2)

ggplot(data = cmat2, mapping = aes(y = coefs2, x = exposure2)) +
  geom_line(linetype = "dashed") +
  geom_point() + 
  geom_errorbar(aes(ymin = (coefs2-1.96*ses2), ymax = (coefs2+1.96*ses2)), width = 0.2) +
  ylim(c(-20, 20)) +
  theme_bw()

```




**Probl?me:** pour l'instant je n'arrive pas ? simuler un dataframe o? l'hypoth?se de parallel trend est v?rifi?e... Notamment, je ne comprends pas le pram?tre \$te.e qui g?n?re une soit-disant dynamique.

-   **DiD package approach**:
#Le code ci-dessous estime les effets moyens du traitement avec l'approche de DiD.
```{r}
# estimate group-group time average treatment effects
did_att_gt <- att_gt(yname = "Y",
                     tname = "period",
                     idname = "id",
                     gname = "G",
                     data = data,
                     bstrap = TRUE, # set to FALSE for pointwise confidence intervals for group-time average treatment effects
                     cband = TRUE) # set to FALSE for pointwise confidence intervals for group-time average treatment effects

summary(did_att_gt)
```

```{r}
# estimate group-group time average treatment effects
did_att_gt2 <- att_gt(yname = "Y",
                     tname = "period",
                     idname = "id",
                     gname = "G",
                     data = data2,
                     bstrap = TRUE,# set to FALSE for pointwise confidence intervals for group-time average treatment effects
                     cband = TRUE, 
                     panel = FALSE) # set to FALSE for pointwise confidence intervals for group-time average treatment effects

summary(did_att_gt2)
```


#Le code agrège les résultats de l'estimation des effets moyens du traitement et crée un graphique
```{r}
# aggregate them into event study plot
did_es <- aggte(did_att_gt, type = "dynamic")

# plot the event study
ggdid(did_es)
```

```{r}
# aggregate them into event study plot
did_es2 <- aggte(did_att_gt2, type = "dynamic")

# plot the event study
ggdid(did_es2)
```

Si le *Pre* treatment has a coefficient close to zero, then the parallel trend assumption holds.

#### Group-time average treatment effects

**Selective treatment timing** means that individuals in different groups experience systematically different effects of participating in the treatment from individuals in other groups. For example, there would be selective treatment timing if individuals choose to be treated in earlier periods if they tend to experience larger benefits from participating in the treatment. This sort of selective treatment timing is likely to be present in many applications in economics / policy evaluation.

When there is **selective treatment timing** then $\mu_l$ end up being weighted averages of treatment effects across different lengths of exposures.

Contrary to event study regressions, pre-tests based on group-time average treatment effects (or based on group-time average treatment effects that are aggregated into an event study plot) are still valid even in the presence of selective treatment timing.
#Le code génère un autre ensemble de données, où le traitement a un effet qui varie dans le temps.
```{r}
# generate selective treatment timing
# (*** this is what is different here ***)
sim_parameters$te.bet.ind = time.periods:1 / (time.periods/2)

# generate data set
data <- build_sim_dataset(sim_parameters)
```

-   **Event-study regression approach**:
#Le code génère des variables indicatrices représentant les périodes de temps précédents et suivante par rapport à chaque période. Puis, on effectue une régression. 
```{r}
# generate leads and lags of the treatment
Dtl <- sapply(-(time.periods-1):(time.periods-2), function(l) {
    dtl <- 1*( (data$period == data$G + l) & (data$G > 0) )
    dtl
})
Dtl <- as.data.frame(Dtl)
cnames1 <- paste0("Dtmin", (time.periods-1):1)
colnames(Dtl) <- c(cnames1, paste0("Dt", 0:(time.periods-2)))
data <- cbind.data.frame(data, Dtl)
row.names(data) <- NULL

# run event study regression
# normalize effect to be 0 in pre-treatment period
es <- plm(Y ~ Dtmin3 + Dtmin2 + Dt0 + Dt1 + Dt2, 
          data = data, model = "within", effect = "twoways", 
          index = c("id", "period"))

summary(es)
```
#On visualise l'impact des évènements temporels sur la variable dépendante. 
```{r}
# some housekeeping for making the plot
# add 0 at event time -1
coefs1 <- coef(es)
ses1 <- sqrt(diag(summary(es)$vcov))
idx.pre <- 1:(time.periods-2)
idx.post <- (time.periods-1):length(coefs1)
coefs <- c(coefs1[idx.pre], 0, coefs1[idx.post])
ses <- c(ses1[idx.pre], 0, ses1[idx.post])
exposure <- -(time.periods-1):(time.periods-2)

cmat <- data.frame(coefs=coefs, ses=ses, exposure=exposure)

# new event study plot
ggplot(data = cmat, mapping = aes(y = coefs, x = exposure)) +
  geom_line(linetype = "dashed") +
  geom_point() + 
  geom_errorbar(aes(ymin = (coefs-1.96*ses), ymax = (coefs+1.96*ses)), width = 0.2) +
  ylim(c(-2, 5)) +
  theme_bw()
```

-   **DiD package approach**:

```{r}
# estimate group-group time average treatment effects
did.att.gt <- att_gt(yname = "Y",
                     tname = "period",
                     idnam = "id",
                     gname = "G",
                     data = data
                     )
# summary(did.att.gt)

# aggregate them into event study plot
did.es <- aggte(did.att.gt, type = "dynamic")

# plot the event study
ggdid(did.es)
```

### Effect estimation

The did package is only built to handle **staggered treatment adoption designs**. This means that once an individual becomes treated, they remain treated in all subsequent periods.

-   Estimating **group-time average treatment effects**:
#On estime les effets moyens du traitement au niveau du groupe et du temps. 

```{r}
# estimate group-time average treatment effects using att_gt method
example_attgt <- att_gt(yname = "Y",
                        tname = "period",
                        idname = "id",
                        gname = "G",
                        xformla = ~X,
                        data = data
                        )

# summarize the results
summary(example_attgt)
```

```{r}
# plot the results
ggdid(example_attgt)
```

-   **Aggregating group-time average treatment effects**:

We can compute a simple aggregation :

```{r}
agg.simple <- aggte(example_attgt, type = "simple")
summary(agg.simple)
```

Or get the dynamic effect:

```{r}
agg.es <- aggte(example_attgt, type = "dynamic")
summary(agg.es)
ggdid(agg.es)
```

-   **Group-Specific Effects**:

Another idea is to look at average effects specific to each group. It is also straightforward to aggregate group-time average treatment effects into group-specific average treatment effects.

```{r}
agg.gs <- aggte(example_attgt, type = "group")
summary(agg.gs)
ggdid(agg.gs)
```

-   **Selecting Alternative Control Groups**:

By default, the did package uses the group of units that never participate in the treatment as the control group. In this case, if there is no group that never participates, then the did package will drop the last period and set units that do not become treated until the last period as the control group (this will also throw a warning). The other option for the control group is to use the "not yet treated". The "not yet treated" include the never treated as well as those units that, for a particular point in time, have not been treated yet (though they eventually become treated). This group is at least as large as the never treated group though it changes across time periods. To use the "not yet treated" as the control, set the option control_group="notyettreated".
# Cette fois ci, on estime les effets moyens du traitement avec une spécification du groupe de contrôle alternative.
```{r}
example_attgt_altcontrol <- att_gt(yname = "Y",
                                   tname = "period",
                                   idname = "id",
                                   gname = "G",
                                   xformla = ~X,
                                   data = data,
                                   control_group = "notyettreated"          
                                   )
summary(example_attgt_altcontrol)
```

-   **Repeated cross sections**:

The did package can also work with repeated cross section rather than panel data. If the data is repeated cross sections, simply set the option panel = FALSE. In this case, idname is also ignored. From a usage standpoint, everything else is identical to the case with panel data.

-   **Unbalanced Panel Data**:

By default, the did package takes in panel data and, if it is not balanced, coerces it into being a balanced panel by dropping units with observations that are missing in any time period. However, if the user specifies the option allow_unbalanced_panel = TRUE, then the did package will not coerce the data into being balanced. Practically, the main cost here is that the computation time will increase in this case.

# Continuous treatment / multiple periods

```{r}
# set simulation parameters
# (main thing: it generates a dataset that satisfies
# parallel trends in all periods...including pre-treatment)
time.periods = 2

sim_parameters = reset.sim(time.periods = time.periods, n = 5000, ipw = TRUE, reg = TRUE)

# generate dynamic effects
sim_parameters$te.e = 1:time.periods

# generate data set
data <- build_sim_dataset(sim_parameters)

head(data, 40)
```

```{r}
#' @title reset.sim
#' @description a function to create a "reasonable" set of parameters
#'  to create simulated panel data that obeys a parallel trends assumption.
#'  In particular, it provides parameters where the the effect of participating
#'  in the treatment is equal to one in all post-treatment time periods. Si on a été traité il y a un an c'est le même effet que si on avait été traité y a 2 ans
#' 
#'  After calling this function, the user can change particular values of the
#'  parameters in order to generate dynamics, heterogeneous effects across
#'  groups, etc.
#'
#' @param time.periods The number of time periods to include
#' @param n The total number of observations
#' @param ipw If TRUE, sets parameters so that DGP is
#'  compatible with recovering ATT(g,t)'s using IPW (i.e.,
#'  where logit that just includes a linear term in X works).  If
#'  FALSE, sets parameters that will be incompatible with IPW.
#'  Either way, these parameters can be specified by the user
#'  if so desired.
#' @param reg If TRUE, sets parameters so that DGP is compatible
#'  with recovering ATT(g,t)'s using regressions on untreated
#'  untreated potential outcomes.  If FALSE, sets parameters that
#'  will be incompatible with using regressions (i.e., regressions
#'  that include only linear term in X).  Either way, these
#'  parameters can be specified by the user if so desired.
#'
#' @return list of simulation parameters
#' 
#' @export
reset.sim <- function(time.periods=4, n=5000, ipw=TRUE, reg=TRUE) {
  #-----------------------------------------------------------------------------
  # set parameters
  #-----------------------------------------------------------------------------
  # coefficient on X 
  bett <- seq(1:time.periods)
  # time fixed effect
  thet <- seq(1:time.periods)
  # time fixed effect
  theu <- thet # changing this creates violations of parallel trends
  # covariate effect
  betu <- bett # changing this creates violations of conditional parallel trends
  #-----------------------------------------------------------------------------
  # parameters for treated potential outcomes
  #-----------------------------------------------------------------------------
  te.bet.ind <- rep(1,time.periods) # no selective treatment timing
  te.bet.X <- bett #no heterogeneous effects by X
  te.t <- thet # no calendar time effects
  te.e <- rep(0,time.periods) # no dynamic effects
  te <- 1 # overall basic effect
  # parameters in generalized propensity score
  # don't make them too big otherwise can get divide by 0
  gamG <- c(0,1:time.periods)/(2*time.periods)

  # return list of parameters
  list(time.periods=time.periods,
       bett=bett,
       thet=thet,
       theu=theu,
       betu=betu,
       te.bet.ind=te.bet.ind,
       te.bet.X=te.bet.X,
       te.t=te.t,
       te.e=te.e,
       te=te,
       n=n,
       gamG=gamG,
       ipw=ipw,
       reg=reg
       )
}

#' @title build_sim_dataset
#'
#' @description A function for building simulated data
#'
#' @param sp_list A list of simulation parameters.  See `reset.sim` to generate
#'  some default values for parameters
#' @param panel whether to construct panel data (the default) or repeated
#'  cross sections data
#'
#' @return a data.frame with the following columns
#'   \itemize{
#'     \item G observations group
#'     \item X value of covariate
#'     \item id observation's id
#'     \item cluster observation's cluster (by construction there is no within-cluster correlation)
#'     \item period time period for current observation
#'     \item Y outcome
#'     \item treat whether or not this unit is ever treated
#'   }
#'
#' @export
build_sim_dataset <- function(sp_list, panel=TRUE) {
  #-----------------------------------------------------------------------------
  # build dataset
  #-----------------------------------------------------------------------------
  time.periods <- sp_list$time.periods
  nt <- sp_list$nt
  bett <- sp_list$bett
  thet=sp_list$thet
  nu <- sp_list$nu
  theu <- sp_list$theu
  betu <- sp_list$betu
  te.bet.ind <- sp_list$te.bet.ind
  te.bet.X <- sp_list$te.bet.X
  te.t <- sp_list$te.t
  te.e <- sp_list$te.e
  te <- sp_list$te
  n <- sp_list$n
  gamG <- sp_list$gamG
  ipw <- sp_list$ipw
  reg <- sp_list$reg

  X <- rnorm(n)

  if (ipw) {
    pr <- exp(outer(X,gamG)) / apply( exp(outer(X,gamG)), 1, sum)
  } else {
    pr <- exp(outer((pnorm(X)+0.5)^2,gamG)) / apply( exp(outer((pnorm(X)+0.5)^2,gamG)), 1, sum)
  }

  G <- apply(pr, 1, function(pvec) sample(seq(0,time.periods), size=1, prob=pvec))

  Gt <- G[G>0]
  nt <- length(Gt)

  if (reg) {
    Xmodel <- X
  } else {
    Xmodel <- X^2
  }

  Xt <- Xmodel[G>0]

  # draw individual fixed effect
  Ct <- rnorm(nt, mean=G)

  # generate untreated potential outcomes in each time period
  Ynames <- paste0("Y",1:time.periods)
  #Ynames <- paste0(1:time.periods)
  Y0tmat <- sapply(1:time.periods, function(t) {
    thet[t] + Ct + Xt*bett[t] + rnorm(nt)
  })
  Y0tdf <- as.data.frame(Y0tmat)
  
  # generate treated potential outcomes
  Y1tdf <- sapply(1:time.periods, function(t) {
    te.t[t] + te.bet.ind[Gt]*Ct + Xt*te.bet.X[t] + (Gt <= t)*te.e[sapply(1:nt, function(i) max(t-Gt[i]+1,1))] + te + rnorm(nt) # hack for the dynamic effects but ok
  })

  # generate observed data
  Ytdf <- sapply(1:time.periods, function(t) {
    (Gt<=t)*Y1tdf[,t] + (Gt>t)*Y0tdf[,t]
  })
  colnames(Ytdf) <- Ynames

  # store observed data for treated group
  dft <- cbind.data.frame(G=Gt,X=X[G>0],Ytdf)

  # untreated units

  # draw untreated covariate
  nu <- sum(G==0)
  Xu <- Xmodel[G==0]

  # draw untreated fixed effect
  Cu <- rnorm(nu, mean=0)


  # generate untreated potential outcomes
  Y0umat <- sapply(1:time.periods, function(t) {
    theu[t] + Cu + rnorm(nu) + Xu*betu[t]
  })
  Y0udf <- as.data.frame(Y0umat)
  colnames(Y0udf) <- Ynames

  # store dataset of observed outcomes for untreated units
  dfu <- cbind.data.frame(G=0,X=X[G==0],Y0udf)

  # store overall dataset
  df <- rbind.data.frame(dft, dfu)

  # generate id variable
  df$id <- 1:nrow(df)
  # generate clusters (there's no actual within-cluster correlation)
  df$cluster <- sample(1:50, size=nrow(df), replace=TRUE)

  # convert data from wide to long format
  ddf <- tidyr::pivot_longer(df,
                             cols=tidyr::starts_with("Y"),
                             names_to="period",
                             names_prefix="Y",
                             values_to="Y")
  ddf$period <- as.numeric(ddf$period)
  ddf$treat <- 1*(ddf$G > 0)
  ddf <- ddf[order(ddf$id, ddf$period),] # reorder data

  if (!panel) { # repeated cross sections
    n <- nt+nu
    Time <- sample(1:time.periods, size=n, replace=TRUE, prob=rep(1/time.periods, time.periods))
    right.row <- sapply( unique(ddf$id), function(i) {
      which(ddf$id==i & ddf$period==Time[i])
    })
    ddf <- ddf[right.row,]
  }

  ddf <- subset(ddf, G != 1)
  ddf
}


#' @title sim
#' @description An internal function that builds simulated data, computes
#'  ATT(g,t)'s and some aggregations.  It is useful for testing the inference
#'  procedures in the `did` function.
#'
#' @inheritParams reset.sim
#' @inheritParams build_sim_dataset
#'
#' @param ret which type of results to return.  The options are `Wpval` (returns
#'  1 if the p-value from a Wald test that all pre-treatment ATT(g,t)'s are equal
#'  is less than .05),
#'  `cband`  (returns 1 if a uniform confidence band covers 0 for groups and times),
#'  `simple` (returns 1 if, using the simple treatment effect aggregation results
#'  in rejecting that this aggregated treatment effect parameter is equal to 0),
#'  `dynamic` (returns 1 if the uniform confidence band from the dynamic treatment
#'  effect aggregation covers 0 in all pre- and post-treatment periods).  The default
#'  value is NULL, and in this case the function will just return the results from
#'  the call to `att_gt`.
#' @param bstrap whether or not to use the bootstrap to conduct inference (default is TRUE)
#' @param cband whether or not to compute uniform confidence bands in the call to `att_gt`
#'  (the default is TRUE)
#' @param control_group Whether to use the "nevertreated" comparison group (the default)
#'  or the "notyettreated" as the comparison group
#' @param xformla Formula for covariates in `att_gt` (default is `~X`)
#' @param est_method Which estimation method to use in `att_gt` (default is "dr")
#' @param clustervars Any additional variables which should be clustered on
#' @param panel whether to simulate panel data (the default) or otherwise repeated
#'  cross sections data
#' 
#' @return When `ret=NULL`, returns the results of the call to `att_gt`, otherwise returns
#'  1 if the specified test rejects or 0 if not.
#' 
#' @export

sim <- function(sp_list,
                ret=NULL,
                bstrap=TRUE,
                cband=TRUE,
                control_group="nevertreated",
                xformla=~X,
                est_method="dr",
                clustervars=NULL,
                panel=TRUE) {

  ddf <- build_sim_dataset(sp_list=sp_list,
                           panel=panel)

  time.periods <- sp_list$time.periods
  te.e <- sp_list$te.e
  te <- sp_list$te
  
  # get results
  res <- att_gt(yname="Y", xformla=xformla, data=ddf, tname="period", idname="id",
                gname="G", 
                bstrap=bstrap, cband=cband, control_group=control_group,
                est_method=est_method,
                clustervars=clustervars,
                panel=panel)


  if (is.null(ret)) {
    return(res)
  } else if (ret=="Wpval") {
    rej <- 1*(res$Wpval < .05)
    return(rej)
  } else if (ret=="cband") {
    cu <- res$att + res$c*res$se 
    cl <- res$att - res$c*res$se
    covers0 <- 1*(all( (cu > 0) & (cl < 0)))
    return(covers0)
  } else if (ret=="simple") {
    agg <- aggte(res)
    rej <- 1*( abs(agg$overall.att / agg$overall.se) > qnorm(.975) )
    return(rej)
  } else if (ret=="dynamic") {
    truth <- c(rep(0,(time.periods-2)),te+te.e[1:(time.periods-1)])
    agg <- aggte(res, type="dynamic")
    cu <- agg$att.egt + agg$crit.val.egt * agg$se.egt
    cl <- agg$att.egt - agg$crit.val.egt * agg$se.egt
    coverstruth <- 1*(all( (cu > truth) & (cl < truth)))
    return(coverstruth)
  } else if (ret=="notyettreated") {
    agg <- aggte(res)
    rej <- 1*( abs(agg$overall.att / agg$overall.se) > qnorm(.975) )
    return(rej)
  } else {
    return(res)
  }

}

## pretest_sim <- function(ret=NULL, bstrap=FALSE, cband=FALSE,
##                         control.group="nevertreated", panel=TRUE, xformla=~X, cores=1) {
## ok on est la
##   ddf <- build_ipw_dataset(panel=panel)

##   # get results
##   res <- conditional_did_pretest(yname="Y", xformla=xformla, data=ddf,
##                                  tname="period", idname="id",
##                                  first.treat.name="G", estMethod="ipw",
##                                  printdetails=FALSE,
##                                  bstrap=bstrap, cband=cband,
##                                  control.group=control.group,
##                                  panel=panel, 
##                                  pl=TRUE, cores=cores)

##   res$CvMpval
## }
```

